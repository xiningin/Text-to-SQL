### 1. 问题定义

鲁棒和泛化其实本身有一些直觉上的定义，鲁棒一般被认为是针对输入的变化，是否能保持输出的能力，这里输入的变化往往是某种类型的扰动，比如噪音、同义变化等等。泛化是指对变化的输入，是否能保持输出的能力，这里的变化的输入往往是指输入的整体具有分布上的差异，比如领域、风格等等。这里比较含糊的一点是，如果对文本数据做了一些语言风格上的变化，到底算是鲁棒还是泛化？你可以再想一想，根据具体场景不同会有一些不同情况。
> 对于语言风格上的变化，如果将这些语言风格的变化看作是针对特定的噪声、异常值或干扰的处理，就算鲁棒性。如果将这些语言风格的变化看作是增强模型对于未见过的数据的适应能力，就算泛化性。例如，在一些特定的自然语言查询任务中，用户可能会使用不规范的语言或者口头语，这就会引入一些噪声和干扰，模型需要具备一定的鲁棒性，才能够正确地解析这些查询。而在一些跨领域的自然语言查询任务中，不同领域的用户可能会使用不同的专业术语或缩写(如查询"使用BERT的语言模型有哪些？")，模型需要具备一定的泛化性，才能够适应不同的领域和场景。

不管是鲁棒还是泛化，本质上都是希望模型真正学到解决问题的能力，而不是受到训练数据规模或者数据特点的局限，展现出过于乐观的性能估计。那么，对于现在的T2S研究，到底是鲁棒更重要还是泛化更重要呢？是否在上面的定义下，可以有一些判断？

> 我认为现在的T2S研究泛化性更重要，第一点是现在很多模型，在代表泛化性的Spider dk上表现不佳(列数据，如Graphix-T5、DocuT5等)。对于希望模型学到解决问题的能力方面，让模型理解自然语言中包含领域知识，或者对于我们人类来说很明显的省略、俗语、习惯性叫法等十分重要。第二点是，一般的准确率、泛化性和鲁棒性可以看作是模型能力提升过程中需要解决的问题，我认为泛化性更多应该在解决鲁棒性之前解决，鲁棒性更像是锦上添花的感觉。

### 2. 数据集

顺着上面的区分，你应该可以对现有数据集做一些判定，他们关注的到底是哪一种问题。如果下一步要开展这方面的研究，到底应该以哪个数据集为主要评估标准。
>   Spider：关注模型对于Text-to-SQL领域任务，理解自然语言问题以及数据库的结构化信息并且生成SQL语句回答问题的能力。
Spider dk：关注模型泛化性问题。重点关注对于需要有一定领域知识或者常识知识才能回答的问题。
Spider realisitc：与Spider syn有部分类似，关注模型对于自然语言问题的理解上，目的是避免模型直接用过问题中的单词匹配数据库中的列或者表。
后续如果开展对于泛化性的研究，应该以Spider dk数据集为主要评估标准。

### 3. 方法

那么到底怎么样才能提升模型的能力呢？一方面是理解文本，你觉得T5能够理解给定了文本了吗？一方面是生成，你觉得T5能够得到符合要求的生成结果了吗？当然你还提到他们之间的对应（模态对齐），这也是很好的切入点。能不能再思考一下，对下一步可能的方向做一些陈述和判断？

> 我认为T5能够理解给定的文本(我理解的这里的文本包括自然语言问题和数据库schma信息)，且生成的SQL语句符合要求的结果。在MIGA这篇论文中的案例分析中，可以基本看出T5-3B模型能给出令人满意的答案，而且这类似zero-shot。Graphix-T5这篇论文的案例分析部分举例探究了在有一定同义扰动的Spider syn上表现则略微乏力。

