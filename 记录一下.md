## 上次我的理解
目前单轮text2sql任务中sota模型准确率综合可达79%左右使用的是基于T5模型并在编码器部分加以图注意机制，在解码器后端加入PICARD模型(模型中有对AST的使用，但与先前提到的AST解码不同)。该模型仍然存在的问题或者可以继续优化的方向是模型的鲁棒性与健壮性，具体可以使用合成数据的方法，得到具有特定针对方向扰动的新的训练数据，该部分在第二篇调研报告(Text-to-SQL前沿技术调研.pdf)中有更详细的阐述。对于多轮任务，先前的调研结果并不正确，近半年该领域仍在继续发展，当前sota模型为MIGA，同样在第二篇报告中有更详细的阐述。

对于text2sql本质的困难，我总结出了以下几点：1、自然语言与SQL结构化语言之间的隔阂；2、模型理解自然语言问题后解决该问题的思路；3、模型如何将自然语言问题与数据库元素以及schema三者建立联系，并理解该联系；4、从中间隐藏张量生成SQL语句需要符合语法规范以及与数据库内容对应；5、该领域内对单/多轮任务模型评价指标不够好；6、多轮任务模型中随着轮次的提升，回答效果降低，并且部分模型只能进行有限轮次QA。

其中1，2已经由NLP中预训练模型解决，3则在text2sql领域近年如RATSQL等的研究中提出解决方法，4由近期提出的PICARD模型以及AST解码解决，5并未得到解决，属于难题，可能暂时没法解决，6在CQR-SQL模型中得到解决。但是对于问题的解决只是能在一定程度上降低这些困难的影响，未来仍然可能存在对当前解决方法的更有效的改进，关于当前sota模型的改进见解，我在第二篇报告的第三节有阐述。
## Question：
我看了你之前的报告和后来补充的对arxiv论文的阅读，从自然语言的角度完成的还不错，辛苦你了。从结构化知识的角度来看，可能很多内容都在文字中体现了，有一些思考又体现在各个小标题中的讨论里，对整体这些研究的框架和变化趋势的表述似乎不是很明确。我想有以下几个方向可以再进一步讨论一下，供你参考！
1. 单轮问题的深入分析： 目前单轮的sota是79%左右，这种模型从性能上讲是否还有进一步提升的空间？还存在的问题是什么？你调研中提到的鲁棒性问题，是单轮目前的最主要问题吗？数据增强（使用合成数据）的方法是解决鲁棒性问题的有效手段吗？
> 从性能上讲，模型本身关于图注意机制和T5的融合不够充分，还存在的问题是模型鲁棒性方面，确实不够优秀，不及在Spider上准确率较低的RESDSQL。对于Graphix-T5这个模型我认为其与多模态任务有些类似(文本图片多模态分类任务)，自然语言是一种模态，数据库Schema是另一种模态，文章中
> 解决鲁棒性问题方面，一些模型是本身具有的鲁棒性，通用性效果潜力强，而对于一个固定的模型框架，提升模型鲁棒性可以通过1.使用合成数据训练2.借鉴TKK:任务分解->知识获取->知识合成本的训练策略(能解决同义词替换类型的问题)3.对抗训练(使用合成数据训练就是一种对抗训练，且比提出的这篇文章用的效果好)
> 目前很多模型评估鲁棒性的方法都是用Spider dk、Spider syn以及Spider realistic如TKK、Graphix-T5、RESDSQL。多轮任务如MIGA并未对鲁棒性有阐述。
> 使用合成数据的方法能有效提升模型的鲁棒性，虽然这对工业界十分友好，但是对于学术研究领域，免不了类似作弊的嫌疑。因此对于解决鲁棒性问题，我更倾向于将重心置于改变模型结构方面入手。
2. 多轮问题的难点与挑战：与单轮相比，多轮即可以看做是多个单轮的组合也可以看做是一个全新的问题。那跟单轮的研究相比，多轮带来的新的难点和挑战在什么地方呢（比如多轮之间的关联建模）？有没有针对性的改进，是否有更巨大的发展空间？
> 多轮任务带来的新难点和挑战在于前后轮次之间的上下文关联，用户可能因为上一个问题而在第二个问题中使用代词省略或者突然改变主题等(引用、省略、更换)。如何使用前面轮次的用户问题以及输出SQL就成了一个巨大挑战(多轮对话中的上下文依赖)。为了解决上下文依赖，模型不仅要理解共引用和省略，还要防止用户焦点变化时不相关的信息集成。
> 本文关注——对话式问题再造(CQR) -> 1.模式增强的递归CQR 2.下文中用于文本到sql的潜在CQR学习。甚至使用CQR，可以将多轮任务转化为单轮任务。(训练时记得鼓励CQR模型更关心问题上下文中引用和省略，对于用户的注意力改变感觉可以通过一个分类实现)
> 另外看到的就是对话系统与多轮Text-to-SQL任务相似性较高，

3. 评价指标方面：印象里你提到有一些with value表现好的模型在match指标中反而较差，这本身是不是一个比较大的问题？
> with value注重的是SQL语句运行出的结果是否正确，而match指标是生成的SQL语句与标准SQL语句进行比较，此部分的提出可以平衡with value指标假阳性的问题。此外在论文Dr.Spider中使用的是with value作为主要评价指标，文章认为“with value指标评估SQL值的正确性，这是模型鲁棒性的重要组成部分”
> 我认为一些with value表现好的模型在match指标中表现差可能是因为模型本身生成SQL语句时不考虑SQL语句的风格，如RESDSQL模型，其在生成部分就属于偏向模板化，因此生成的SQL语句一般会与gold SQL有一定差距(其中去除了所有使用AS的，以及规定order后面的一定加上_asc等)。
> with value出现的假阳性(其中出现情况最多的是结果为NULL的，对此可以使用实验验证，在dev数据集中使用极少甚至没有NULL结果的数据，这样with value指标的评价就是较为准确的了)出现几率明显小于match中的假阴性，因为同一个SQL，因为书写风格不同可以有许多中不同的形式，这些问题都会带来match指标的偏小。从实际应用方面来说，我们也是更关注with value的值得，至于with value与match指标差距过大，我认为本身不是一个比较大的问题。

总体上看，预训练模型比如T5，是肯定要用的基础模型，PICARD用来对结果进行验证，也是必然的框架，你觉得这个框架还缺少些什么吗？这个框架本身还有可以进一步改进的地方吗？
> 缺少常识知识，框架在T5部分可以使用领域知识进行训练，这部分能在应对Spider dk类问题时有较好的鲁棒性提升。
> 在改进方面我有三个方向的想法：
1.如果是从多模态的角度出发，将数据库schema和自然语言问题看成两个不同模态。Graphix-T5本身在Encoding阶段是在每一层，对schema和nlq分别计算，然后加和，然后再传递进入下一层。从多模态领域的角度来说，该框架可能缺少两个模态之间的fusion，实现双塔结构作为Encoding部分。RESDSQL中提到的使用图编码器可能在泛化性(换一个数据库)上有点不行，有点依赖数据库的设计。多模态式的方法可能会在对数据库Schema那方面的影响下有所改变。

## tmp notes
单轮的sota:Graphix-T5。首先第一步看的重点应该是text2sql的鲁棒性这个。
- RESDSQL: Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL
> AAAI2023
> 这篇论文是说自己实现了Seq2Seq结构中sql生成时schema linking 和 skeleton parsing的解耦，说是解决了鲁棒性问题。
**可能可以借鉴的点：**
(1)Encoding Module方面，考虑到tokenizer容易将table名字或者column名字tokenize成多个token，eg:将user id分别解析为两个，而我们可能更多需要user id整个的语义(虽说这个主要是为了这里最开始的cross-encoding分类，或许能对其他模型有所启发)。改进方法为对属于同一schema item的token进行pool(文章使用了两层BiLSTM和一个非线性全连接层)
(2)文中还考虑到问题中可能直接用的column，导致被忽略的table名得分较低，排名不高，因此有了Column-enhanced Layer，这个也算是用的注意力机制的一个公式。
(3)文中对于Spider数据集初始规范了一下，消除数据本身不同SQL语句的不同风格的影响，减少模型学习压力
(4)本文对于鲁棒性这方面使用的Spider-DK、Spider-Syn、Spider-Realistic这三个Spider数据集的变体(这些东西本身就是对于Spider数据集在鲁棒性方面做出的修改版数据集)
(5)本文在相关工作中提到对图编码器的认识时，认为图编码器严重依赖关系的设计，可能限制其在其他数据集上的鲁棒性和通用性。
(6)本文总得来说突出一个"解耦"，降低自然语言与SQL语言之间差异对模型的难度影响，在输入开头先按照优先级硬筛选相关schema items，在输出先生成骨架后插槽填入，通过分解任务降低了整体任务难度。
**模型结果：**
鲁棒性方面，在使用Spider的三个变体数据集测试后结果比其他的好贼多，文中认为是他们提出的交叉编码器可以减轻模式链接的困难，从而在问题扰动方面出现了鲁棒性。
**一些吐槽：**
但是说实话结果确实比不上Graphix-T5，其在EM和EX上差距较大感觉是因为模型本身生成SQL的策略，并未学习不同SQL语句的风格，更注重于结果了，因此在与gold SQL比较时被判错，有一定的假阴性。
**需要关注的点：**
Spider数据集的三个变体以及提出其的论文说不定在鲁棒性上有一定的指导。Graphix-T5在这三个变体数据集上面只说的EM，但是这个EM略次于RESDSQL(这个模型本身EM就有可能出现假阳性，由此可以见Graphix-T5的鲁棒性不是太好)，Graphix-T5里面用了一个Spider-SSP的一个组合数据，可以看看那个是什么的

- 提出Spider dk的Exploring Underexplored Limitations of Cross-Domain Text-to-SQL Generalization
> EMNLP2021
> Spider dk是一个基于Spider基准的人工管理数据集，用于评估文本到sql模型的泛化，重点是理解领域知识。
> 该变体重点是评估领域知识的模型理解。文章提出跨域text2sql泛化的一个主要挑战是理解不同域所需的不同知识。提高模型获取领域知识的能力是实现text2sql应用跨领域泛化的重要方向。
> 构建Spider-DK的目的是模拟用户话语查询中涉及特定领域知识的场景。领域知识经常被不注意地使用，这使得一些领域知识不可避免。一个例子就是“Q:How many students got accepted after the tryout? 这个的SQL语句中应该使用的判断是from tryout where decision="yes"，需要模型有基础知识背景以了解accepted是什么意思”。

- 提出Spider syn的Towards Robustness of Text-to-SQL Models against Synonym Substitution
> ACL2021
> Spider syn是对于text2sql领域模型鲁棒性问题，考虑到现有的text2sql模型通常依赖于自然语言(NL)问题中的单词和表模式中的标记之间的词汇匹配提出的基于Spider基准的人工管理数据集，其主要从同义词方面研究，使用的同义词多是生活中常用的，且只对与数据库表、列名相关的词进行替换。
> 本文也提出了两类提高这方面鲁棒性的方法。1.通过在模型输入做修改，添加额外同义词注释(更有效果)。2.使用对抗训练。

- 提出Spider realistic的Structure-Grounded Pretraining for Text-to-SQL
> NAACL2021
> 这篇文章本身主要是提出一种新的弱监督结构基础预训练框架，为了在更真实的文本表中应用该训练框架，文章提出了Spider realistic，这个数据集可以看成是类似Spider syn，但是是把一些较长的半句替换(例如把从句换了。换成更符合实际使用时人们输入的语言，就与schema中的名字没那么强的相关性了)。
> 这篇文章提出的table-text也挺值得注意一下的。

- 剔除Spider SSP的
> 组合泛化能力

- Dr.Spider——A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness
> ICLR 2023 引用了这些除了TKK的所有
> 提出了一个基于Spider的综合鲁棒性基准来诊断模型鲁棒性。与Spider syn类似都考虑到模型学岔了(从自然语言问题中寻找与schema匹配的单词而不是理解自然语言问题)。文章使用的合成数据方法从DB、NLQ、SQL三个方向添加扰动，其中包括上述的Spider syn和Spider realistic，但是对于Spider dk方面的领域知识并未说明。本文对于评估模型鲁棒性提出了三个指标，而当前很多论文如Graphix-T5、RESDSQL等都是单纯使用的Spider的三个变体数据进行的鲁棒性评估。(数据与代码已经公开https://github.com/awslabs/diagnostic-robustness-text-to-sql)但是访问是没有的，今年1月28号的文，在Graphix-T5之后发出的，这篇文章里也没有评估Graphix-T5的鲁棒性。这篇文章是单轮Text-to-SQL领域关于鲁棒性最新的研究了。

- Towards Generalizable and Robust Text-to-SQL Parsing(TKK)
> EMNLP2022
> TKK: 任务分解->知识获取->知识合成本文认为这种多阶段学习增强了模型获取一般SQL知识的能力。
> 解决鲁棒性一个重点是实现语义解析而不是匹配。本文还提出泛化(泛化不等同于鲁棒性)可以关注zero-shot generalization(得益于大规模数据集Spider、SParC、CoSQL，zero-shot generalization已经成为近年来文本到sql解析最流行的设置)、compositional generation(在训练过程中观察到的由新组合组成的测试示例进行泛化的所需能力)。模型在测试鲁棒性上仅使用了同义词替换的syn。
> 文中提出的鲁棒性与泛化的区别：泛化性指的是同样的问题，对于不同数据库schema，模型能否给出有效结果(以及能否生成与之前不同的SQL语句)。鲁棒性指的是测试集问题改得更贴近生活，可能有语病等问题等等之类的。

- Towards Robustness of Text-to-SQL Models Against Natural and Realistic Adversarial Table Perturbation
> ACL2022
> 提出对抗表扰动——一种新的攻击范式来衡量Text-to-SQL模型鲁棒性(第一个鲁棒性评估指标——ADVETA)，还构建了一个系统的对抗训练示例生成框架，用于更好地将表格数据上下文化——极大增强了模型对NL侧扰动的抵抗力(Dr. Spider中的NLQ扰动与其类似)
> 关于表的扰动相当于Dr. Spider中的DB扰动(也就是改表的名字那些什么的)，但是这个文章中除了改schema中列名，还有添加列之类的操作，这点是Dr. Spider没有的。
> 里面提出了对抗类似的那个框架不一定对于其他的扰动合适。

- Importance of Synthesizing High-quality Data for Text-to-SQL Parsing
> Amazon 2022
论文提出了生成优质合成数据的一种新的方法，解决了合成数据集过程中面临的问题。文中谈到通过更贴近生活使用的合成数据再次训练模型，能使模型在下游任务的效果进一步提升，并且该论文中通过实验证明使用合成数据训练的 T5-3B+PICARD 模型可以达到接近单轮任务 sota 模型 Graphix-T5 的效果。相比同领域合成数据的方法，本文克服了很多合成数据方法的弊端，在使用 SQL 生成 NLQ 时加入具有直观性的 IR 中间层，使生成NLQ更自然，信息损失最小。

后面开始开多轮任务里的一些论文看看了。

- CONVERSATIONAL TEXT-TO-SQL: AN ODYSSEY INTO STATE-OF-THE-ART AND
CHALLENGES AHEAD
> IEEE 2023
> 多任务训练，good。本文还另外关注zero-shot的泛化性。

## Answer